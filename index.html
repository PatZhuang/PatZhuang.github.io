<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">








  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">














  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-32x32.png?v=7.1.2">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="ğŸŒˆ">
<meta property="og:type" content="website">
<meta property="og:title" content="Pato&#39;s raison d&#39;etre">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Pato&#39;s raison d&#39;etre">
<meta property="og:description" content="ğŸŒˆ">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pato&#39;s raison d&#39;etre">
<meta name="twitter:description" content="ğŸŒˆ">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Pato's raison d'etre</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Pato's raison d'etre</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>é¦–é¡µ</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>æ ‡ç­¾</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>å…³äº</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>å½’æ¡£</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/20/learning-pytorch-with-examples/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/20/learning-pytorch-with-examples/" class="post-title-link" itemprop="url">Learning Pytorch With Examples</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-20 21:55:24 / ä¿®æ”¹æ—¶é—´ï¼š21:56:59" itemprop="dateCreated datePublished" datetime="2019-06-20T21:55:24+08:00">2019-06-20</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html" target="_blank" rel="noopener">LEARNING PYTORCH WITH EXAMPLES</a> çš„å­¦ä¹ ç¬”è®°</p>
<p>æœ¬æ–‡å°†é€šè¿‡ä¸€äº› self-contained çš„ç¤ºä¾‹ä»‹ç» PyTorch çš„ä¸€äº›åŸºæœ¬æ¦‚å¿µã€‚</p>
<p>PyTorch æä¾›ä¸¤ä¸ªä¸»è¦ç‰¹æ€§ï¼š</p>
<ul>
<li>N ç»´çš„ Tensor, å’Œ numpy çš„ ndarray ç±»ä¼¼ï¼Œä½†æ˜¯å¯ä»¥è¿è¡Œåœ¨ GPU ä¸Š</li>
<li>ä¸ºç¥ç»ç½‘ç»œçš„æ„å»ºå’Œè®­ç»ƒæä¾›è‡ªåŠ¨æ±‚å¯¼</li>
</ul>
<p>æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥ ReLU ç½‘ç»œä½œä¸ºç¤ºä¾‹ï¼Œè¯¥ç½‘ç»œåªæœ‰ä¸€ä¸ªéšè—å±‚ï¼Œä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ³•æ¥è®­ç»ƒã€‚æˆ‘ä»¬å°†æœ€å°åŒ–è¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ¥æ‹Ÿåˆä¸€äº›éšæœºæ•°æ®ã€‚</p>
<h2 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h2><h3 id="Warm-up-numpy"><a href="#Warm-up-numpy" class="headerlink" title="Warm-up: numpy"></a>Warm-up: numpy</h3><p>åœ¨å¼•å…¥ PyTorch ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆä½¿ç”¨ numpy æ¥å®ç°è¿™ä¸ªç½‘ç»œã€‚</p>
<p>Numpy æä¾›äº†ä¸€ä¸ª N ç»´æ•°ç»„å¯¹è±¡å’Œä¸€äº›ç”¨äºæ“çºµè¿™ä¸ªæ•°ç»„çš„å‡½æ•°ã€‚Numpy æ˜¯ä¸€ä¸ªç”¨äºç§‘å­¦è®¡ç®—çš„é€šç”¨æ¡†æ¶ï¼Œå®ƒä¸è®¡ç®—å›¾ã€æ·±åº¦å­¦ä¹ å’Œæ¢¯åº¦æ²¡æœ‰ç›´æ¥å…³ç³»ã€‚ä½†æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨ Numpy ç¼–å†™å‰å‘å’Œåå‘ä¼ æ’­æ¥å®ç°ä¸€ä¸ªæ‹Ÿåˆéšæœºæ•°æ®çš„ä¸¤å±‚ç½‘ç»œã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in) <span class="comment"># (64, 1000)</span></span><br><span class="line">y = np.random.randn(N, D_out) <span class="comment"># (64, 10)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H) <span class="comment"># (1000, 100)</span></span><br><span class="line">w2 = np.random.randn(H, D_out) <span class="comment"># (100, 10)</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># (64, 1000) x (1000, 100) = (64, 100)</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># (64, 100)</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># (64, 100) x (100, 10) = (64, 10)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum() <span class="comment"># æ¬§æ°è·ç¦»ï¼šåæ ‡å·®çš„å¹³æ–¹å’Œï¼ˆä¸ºæ–¹ä¾¿æ±‚å¯¼æ²¡æœ‰å¼€æ ¹å·ï¼‰</span></span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>: <span class="comment"># æ¯ 100 æ¬¡è¿­ä»£æ‰“å°ä¸€æ¬¡ loss</span></span><br><span class="line">        print(t, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 w.r.t. loss</span></span><br><span class="line">    <span class="comment"># æ³¨æ„åˆ°æ¯ä¸ªå˜é‡çš„æ¢¯åº¦å’Œå˜é‡æœ¬èº«æœ‰ä¸€æ ·çš„ shape</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y) <span class="comment"># (64, 10)</span></span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred) <span class="comment"># (100, 64) x (64, 10) = (100, 10)</span></span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T) <span class="comment"># (64, 10) x (10, 100) = (64, 100)</span></span><br><span class="line">    grad_h = grad_h_relu.copy() <span class="comment"># (64, 100)</span></span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span> <span class="comment"># ReLU åœ¨å‡½æ•°å€¼å°äº 0 å¤„å¯¼æ•°ä¸º 0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h) <span class="comment"># (1000, 64) x (64, 100) = (1000, 100)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Tensors"><a href="#PyTorch-Tensors" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h3><p>Numpy å¾ˆæ£’ï¼Œä½†å®ƒæ— æ³•ä½¿ç”¨ GPU æ¥åŠ é€Ÿè¿ç®—ã€‚å¯¹äºç°ä»£æ·±åº¦å­¦ä¹ ç½‘ç»œï¼ŒGPU é€šå¸¸è¦æ¯” CPU å¿« 50 å€ä»¥ä¸Šï¼Œå› æ­¤å¾ˆé—æ†¾ï¼ŒNumpy æ— æ³•è¿ç”¨åˆ°ç°ä»£æ·±åº¦å­¦ä¹ ä¸Šã€‚</p>
<p>æˆ‘ä»¬åœ¨æ­¤å¼•å…¥ PyTorch æœ€åŸºç¡€çš„æ¦‚å¿µï¼š<strong><code>Tensor</code></strong>. ä¸€ä¸ª PyTorch Tensor å’Œ Numpy Array åœ¨æ¦‚å¿µæ˜¯æ˜¯å®Œå…¨ç›¸åŒçš„ï¼šTensor æ˜¯ä¸€ä¸ª N ç»´æ•°ç»„ï¼Œä¸” PyTorch æä¾›äº†å¯¹è¿™ä¸ªæ•°ç»„è¿›è¡Œè¿ç®—çš„å¤šç§å‡½æ•°ã€‚ä¸ Numpy Array ä¸åŒçš„æ˜¯ï¼ŒTensor å¯ä»¥è¿½è¸ªè¿ç®—å›¾å’Œæ¢¯åº¦ï¼Œå½“ç„¶å®ƒä¹Ÿå¯ä»¥ç”¨äºé€šç”¨çš„ç§‘å­¦è®¡ç®—ã€‚</p>
<p>Tensor ä¸åŒäº Numpy Array çš„å¦ä¸€ç‚¹åœ¨äºï¼Œå®ƒå¯ä»¥ä½¿ç”¨ GPU æ¥åŠ é€Ÿæ•°å€¼è®¡ç®—ã€‚</p>
<p>ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ Tensor é‡å†™ä¸Šè¿°çš„ä¸¤å±‚ç½‘ç»œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">'cpu'</span>) <span class="comment"># åœ¨ CPU æ‰§è¡Œè®¡ç®—</span></span><br><span class="line"><span class="comment"># device = torch.device('cuda: 0') # åœ¨ GPU æ‰§è¡Œè®¡ç®—</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># mm: matrix multiply</span></span><br><span class="line">    h_relu = h.clamp(<span class="number">0</span>) <span class="comment"># æŠŠæ•°æ® clamp åˆ° (min, [max])</span></span><br><span class="line">    y_pred = h_relu.mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(i, loss)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Backprop</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y) <span class="comment"># (64, 10)</span></span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred) <span class="comment"># (100, 10)</span></span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t()) <span class="comment"># (64, 100)</span></span><br><span class="line">    grad_h = grad_h_relu.clone() <span class="comment"># (64, 100)</span></span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    </span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h2 id="Autograd"><a href="#Autograd" class="headerlink" title="Autograd"></a>Autograd</h2><h3 id="PyTorch-Tensors-and-autograd"><a href="#PyTorch-Tensors-and-autograd" class="headerlink" title="PyTorch: Tensors and autograd"></a>PyTorch: Tensors and autograd</h3><p>åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å®ç°ç¥ç»ç½‘ç»œçš„å‰å‘å’Œåå‘ä¼ æ’­ã€‚å¯¹äºä¸¤å±‚çš„å°ç½‘ç»œæ¥è¯´ï¼Œæ‰‹åŠ¨å®ç°åå‘ä¼ æ’­é—®é¢˜ä¸å¤§ï¼Œä½†æ˜¯å¯¹äºå¤æ‚çš„ç½‘ç»œæ¥è¯´ï¼Œæ‰‹åŠ¨å®ç°åå‘ä¼ æ’­å°±ä¼šå˜å¾—å¾ˆå›°éš¾ã€‚</p>
<p>æ‰€å¹¸æˆ‘ä»¬å¯ä»¥ä½¿ç”¨<a href="https://en.wikipedia.org/wiki/Automatic_differentiation" target="_blank" rel="noopener">è‡ªåŠ¨å¾®åˆ†ï¼ˆautomatic differentiationï¼‰</a>æ¥è‡ªåŠ¨å®Œæˆåå‘ä¼ æ’­é˜¶æ®µçš„æ¢¯åº¦è®¡ç®—ã€‚PyTorch çš„ <strong>autograd</strong> åŒ…å°±æä¾›äº†è¿™æ ·çš„åŠŸèƒ½ã€‚ä½¿ç”¨ autograd åï¼Œåœ¨ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­çš„è¿‡ç¨‹ä¸­ä¼šå®šä¹‰ä¸€å¼  <strong>è®¡ç®—å›¾ï¼ˆcomputational graphï¼‰</strong>ï¼Œå›¾çš„ç»“ç‚¹æ˜¯ Tensor, è¾¹æ˜¯ç”±è¾“å…¥ Tensor ç”Ÿæˆè¾“å‡º Tensor çš„å¯¹åº”å‡½æ•°ï¼ˆfunctionï¼‰. å¯¹è¿™å¼ å›¾æ‰§è¡Œåå‘ä¼ æ’­å¯ä»¥å¾ˆå®¹æ˜“åœ°è®¡ç®—æ¢¯åº¦ã€‚</p>
<p>è™½ç„¶å¬ä¸Šå»å¤æ‚ï¼Œä½†æ˜¯å®ç°èµ·æ¥æ˜¯å¾ˆå®¹æ˜“çš„ã€‚æ¯ä¸ª Tensor ä»£è¡¨è®¡ç®—å›¾ä¸­çš„ä¸€ä¸ªç»“ç‚¹ã€‚å¦‚æœ <code>x</code> æ˜¯ä¸€ä¸ª Tensor ä¸”å®ƒçš„ <code>requires_grad</code> å±æ€§ä¸º <code>True</code>, åˆ™ <code>x.grad</code> æ˜¯æŒ‡å‘ <code>x</code> å¯¹äºæŸä¸ªæ ‡é‡çš„æ¢¯åº¦çš„ Tensor.</p>
<p>ä¸‹é¢ä½¿ç”¨ autograd æ¥å®ç°ä¸Šè¿°çš„ä¸¤å±‚ç½‘ç»œï¼Œç°åœ¨æˆ‘ä»¬æ— éœ€å†è‡ªå·±å®ç°åå‘ä¼ æ’­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"><span class="comment"># device = torch.device('cuda: 0')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold input and outputs.</span></span><br><span class="line"><span class="comment"># Setting requires_grad=False indicates that we do not need to compute gradients</span></span><br><span class="line"><span class="comment"># with respect to these Tensors during the backward pass.</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors for weights.</span></span><br><span class="line"><span class="comment"># Setting requires_grad=True indicates that we want to compute gradients with</span></span><br><span class="line"><span class="comment"># respect to these Tensors during the backward pass.</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y using operations on Tensors</span></span><br><span class="line">    <span class="comment"># å‰å‘ä¼ æ’­çš„æ“ä½œå’Œä¹‹å‰æ˜¯ä¸€æ ·çš„</span></span><br><span class="line">    <span class="comment"># ä½†æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­ï¼Œå› æ­¤ä¸ç”¨å†ä¿å­˜ä¸­é—´ç»“æœ</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute and print loss using operations on Tensors.</span></span><br><span class="line">    <span class="comment"># Now loss is a Tensor of shape (1,)</span></span><br><span class="line">    <span class="comment"># loss.item() gets the a scalar value held in the loss.</span></span><br><span class="line">    <span class="comment"># è¿™é‡Œä¸è¦ç›´æ¥å–å‡º item(), å› ä¸ºä¸‹é¢è¿˜è¦å¯¹ loss è°ƒç”¨ backward()</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># å¯¹ loss è°ƒç”¨ backward() æ–¹æ³•å¯ä»¥è‡ªåŠ¨è®¡ç®—åå‘ä¼ æ’­çš„æ¢¯åº¦</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨è¯¥æ–¹æ³•åï¼Œw1.grad å’Œ w2.grad ä¼šè¢«è®¡ç®—ï¼Œè¿™ä¸¤è€…åˆ†åˆ«æŒ‡å‘</span></span><br><span class="line">    <span class="comment"># loss å¯¹äº w1 å’Œ w2 çš„æ¢¯åº¦</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ‰‹åŠ¨æ›´æ–°æƒé‡</span></span><br><span class="line">    <span class="comment"># ä½¿ç”¨ torch.no_grad() ä¸Šä¸‹æ–‡çš„åŸå› æ˜¯ï¼Œ w1 å’Œ w2 çš„ requires_grad=True</span></span><br><span class="line">    <span class="comment"># ä½†æ˜¯åœ¨æ›´æ–°æƒé‡çš„è¿‡ç¨‹ä¸­æˆ‘ä»¬ä¸éœ€è¦å¯¹è¿™ä¸ªæ“ä½œè®¡ç®—æ¢¯åº¦ï¼Œå› æ­¤ä¸éœ€è¦è¿½è¸ªè¿™ä¸ªè¿ç®—</span></span><br><span class="line">    <span class="comment"># ä¹Ÿå¯ä»¥ä½¿ç”¨ weight.data å’Œ weight.grad.data æ¥æ›´æ–°æƒé‡</span></span><br><span class="line">    <span class="comment"># Tensor çš„ data å±æ€§æŒ‡å‘çš„ Tensor å’ŒåŸ Tensor å…±äº«å­˜å‚¨ï¼Œä½†å¯¹å…¶çš„è®¡ç®—ä¸ä¼šè¢«è¿½è¸ª</span></span><br><span class="line">    <span class="comment"># å¯ä»¥ä½¿ç”¨ torch.optim.SGD æ¥å®ç°éšæœºæ¢¯åº¦ä¸‹é™</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åœ¨æ›´æ–°æƒé‡åè¦å°†å…¶æ¢¯åº¦ç½®0ï¼Œå¦åˆ™æ¯æ¬¡åå‘ä¼ æ’­ä¼šç´¯åŠ æ¢¯åº¦</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Defining-new-autograd-functions"><a href="#PyTorch-Defining-new-autograd-functions" class="headerlink" title="PyTorch: Defining new autograd functions"></a>PyTorch: Defining new autograd functions</h3><p>æœ¬èŠ‚æ˜¯è‡ªå®šä¹‰ autograd çš„ç›¸å…³æ•™ç¨‹ï¼Œæš‚ç•¥ã€‚</p>
<h3 id="TensorFlow-Static-Graphs"><a href="#TensorFlow-Static-Graphs" class="headerlink" title="TensorFlow: Static Graphs"></a>TensorFlow: Static Graphs</h3><p>æœ¬èŠ‚æ˜¯ TensorFlow çš„é™æ€å›¾æœºåˆ¶çš„ç›¸å…³æ•™ç¨‹ï¼Œæš‚ç•¥ã€‚</p>
<h2 id="nn-module"><a href="#nn-module" class="headerlink" title="nn module"></a>nn module</h2><h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>è®¡ç®—å›¾å’Œè‡ªåŠ¨æ¢¯åº¦æ˜¯å®šä¹‰å¤æ‚æ“ä½œå’Œè‡ªåŠ¨è®¡ç®—å¾®åˆ†çš„å¼ºåŠ›å·¥å…·ï¼Œä½†æ˜¯å¯¹äºå¤§å‹çš„ç¥ç»ç½‘ç»œï¼ŒåŸå§‹çš„ autograd å°±æ˜¾å¾—æœ‰ç‚¹ä½çº§äº†ã€‚</p>
<p>æ„å»ºç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæƒ³æŠŠè®¡ç®—æ’åˆ—ä¸ºå±‚ï¼ˆlayerï¼‰ï¼ŒæŸäº›å±‚æœ‰å¯å­¦ä¹ å‚æ•°ï¼ˆlearnable parametersï¼‰ï¼Œè¿™äº›å‚æ•°å¯ä»¥åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è¢«ä¼˜åŒ–ã€‚</p>
<p>TensorFlow çš„ Keras, TensorFlow-Slib å’Œ TFLearn åŒ…ä¸­æä¾›äº†ç›¸æ¯”åŸå§‹çš„è®¡ç®—å›¾æ›´é«˜å±‚çš„æ¥å£æ¥æ„å»ºç¥ç»ç½‘ç»œã€‚åœ¨ PyTorch ä¸­ï¼Œè¿™æ ·çš„åŒ…æ˜¯ <code>nn</code>. </p>
<p><code>nn</code> å®šä¹‰äº†ä¸€ç³»åˆ—çš„ <strong>æ¨¡å—ï¼ˆModuleï¼‰</strong>ï¼Œç›¸å½“äºç¥ç»ç½‘ç»œä¸­çš„å±‚ï¼ˆLayerï¼‰ã€‚ä¸€ä¸ªæ¨¡å—æ¥å—è¾“å…¥å¼ é‡å¹¶è®¡ç®—è¾“å‡ºå¼ é‡ï¼Œå¹¶ä¿å­˜ä¸­é—´çŠ¶æ€ä¾‹å¦‚æœ‰å¯å­¦ä¹ å‚æ•°çš„ Tensor. <code>nn</code> ä¹Ÿå®šä¹‰äº†ä¸€ç³»åˆ—å¸¸ç”¨çš„æŸå¤±å‡½æ•°ã€‚</p>
<p>ä¸‹é¢ä½¿ç”¨ <code>nn</code> åŒ…æ¥å®ç°ä¸Šè¿°çš„ä¸¤å±‚ç½‘ç»œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model as a sequence of layers. nn.Sequential</span></span><br><span class="line"><span class="comment"># is a Module which contains other Modules, and applies them in sequence to</span></span><br><span class="line"><span class="comment"># produce its output. Each Linear Module computes output from input using a</span></span><br><span class="line"><span class="comment"># linear function, and holds internal Tensors for its weight and bias.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The nn package also contains definitions of popular loss functions; in this</span></span><br><span class="line"><span class="comment"># case we will use Mean Squared Error (MSE) as our loss function.</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span><br><span class="line">    <span class="comment"># override the __call__ operator so you can call them like functions. When</span></span><br><span class="line">    <span class="comment"># doing so you pass a Tensor of input data to the Module and it produces</span></span><br><span class="line">    <span class="comment"># a Tensor of output data.</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute and print loss. We pass Tensors containing the predicted and true</span></span><br><span class="line">    <span class="comment"># values of y, and the loss function returns a Tensor containing the</span></span><br><span class="line">    <span class="comment"># loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    print(t, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Zero the gradients before running the backward pass.</span></span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span><br><span class="line">    <span class="comment"># parameters of the model. Internally, the parameters of each Module are stored</span></span><br><span class="line">    <span class="comment"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span><br><span class="line">    <span class="comment"># all learnable parameters in the model.</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span><br><span class="line">    <span class="comment"># we can access its gradients like we did before.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># å¯ä»¥ç”¨ model çš„ parameters() æ–¹æ³•éå†å…¶æ‰€æœ‰å¯å­¦ä¹ å‚æ•°</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h3><p>åˆ°è¿™ä¸€æ­¥ä¸ºæ­¢æˆ‘ä»¬éƒ½æ˜¯æ‰‹åŠ¨æ›´æ–°ç¥ç»ç½‘ç»œçš„æƒé‡ï¼ˆä½¿ç”¨ <code>torch.no_grad()</code> æˆ–è€… <code>.data</code> æ¥é¿å…è¿½è¸ªæƒé‡æ›´æ–°çš„æ“ä½œï¼‰ã€‚å¯¹äºç®€å•çš„ä¼˜åŒ–ç®—æ³•ä¾‹å¦‚éšæœºæ¢¯åº¦ä¸‹é™æ¥è¯´è¿™å¾ˆå®¹æ˜“ï¼Œä½†æ˜¯æˆ‘ä»¬åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶å¾€å¾€ä½¿ç”¨æ›´å¤æ‚çš„ä¼˜åŒ–å™¨ä¾‹å¦‚ AdaGrad, RMSProp, Adam ç­‰ã€‚</p>
<p>PyTorch çš„ <code>optim</code> åŒ…æä¾›äº†å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•çš„å®ç°ã€‚</p>
<p>ä¸‹é¢ä½¿ç”¨ <code>optim</code> åŒ…æ¥ä¿®æ”¹ä¸Šè¿°ä¸¤å±‚ç¥ç»ç½‘ç»œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model and loss function.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out),</span><br><span class="line">)</span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the optim package to define an Optimizer that will update the weights of</span></span><br><span class="line"><span class="comment"># the model for us. Here we will use Adam; the optim package contains many other</span></span><br><span class="line"><span class="comment"># optimization algoriths. The first argument to the Adam constructor tells the</span></span><br><span class="line"><span class="comment"># optimizer which Tensors it should update.</span></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line"><span class="comment"># ä¼˜åŒ–å™¨çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯éœ€è¦ä¼˜åŒ–çš„å‚æ•°ï¼Œè¿™é‡Œä¼ å…¥æ¨¡å‹çš„æ‰€æœ‰å‚æ•°</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model.</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Before the backward pass, use the optimizer object to zero all of the</span></span><br><span class="line">    <span class="comment"># gradients for the variables it will update (which are the learnable</span></span><br><span class="line">    <span class="comment"># weights of the model). This is because by default, gradients are</span></span><br><span class="line">    <span class="comment"># accumulated in buffers( i.e, not overwritten) whenever .backward()</span></span><br><span class="line">    <span class="comment"># is called. Checkout docs of torch.autograd.backward for more details.</span></span><br><span class="line">    <span class="comment"># å¯¹ä¼˜åŒ–å™¨ï¼ˆè€Œä¸æ˜¯æ¨¡å‹ï¼‰è°ƒç”¨ .zero_grad_() æ¥æ¸…é›¶æƒé‡</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to model</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calling the step function on an Optimizer makes an update to its</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    <span class="comment"># æ³¨æ„ step() æ–¹æ³•åªæ›´æ–°äº†æƒé‡è€Œæ²¡æœ‰å°†æƒé‡æ¸…é›¶</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Custom-nn-Modules"><a href="#PyTorch-Custom-nn-Modules" class="headerlink" title="PyTorch: Custom nn Modules"></a>PyTorch: Custom nn Modules</h3><p>æœ‰æ—¶å€™ä½ ä¼šéœ€è¦å®šä¹‰æ¯”é¡ºåºå †å ç°æœ‰æ¨¡å—çš„é¡ºåºæ¨¡å‹æ›´åŠ å¤æ‚çš„æ¨¡å‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥ä½ å¯ä»¥ç»§æ‰¿ <code>nn.Module</code> å¹¶å®šä¹‰ä¸€ä¸ª <code>forward</code> æ–¹æ³•æ¥å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„ç¥ç»ç½‘ç»œã€‚</p>
<p>ä¸‹é¢ä½¿ç”¨ä¸€ä¸ª <code>nn.Module</code> çš„è‡ªå®šä¹‰å­ç±»æ¥å®ç°ä¸Šè¿°ç½‘ç»œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the constructor we instantiate two nn.Linear modules and assign them as</span></span><br><span class="line"><span class="string">        member variables.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward function we accept a Tensor of input data and we must return</span></span><br><span class="line"><span class="string">        a Tensor of output data. We can use Modules defined in the constructor as</span></span><br><span class="line"><span class="string">        well as arbitrary operators on Tensors.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        h_relu = self.linear1(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.linear2(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our model by instantiating the class defined above</span></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our loss function and an Optimizer. The call to model.parameters()</span></span><br><span class="line"><span class="comment"># in the SGD constructor will contain the learnable parameters of the two</span></span><br><span class="line"><span class="comment"># nn.Linear modules which are members of the model.</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: Compute predicted y by passing x to the model</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero gradients, perform a backward pass, and update the weights.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Control-Flow-Weight-Sharing"><a href="#PyTorch-Control-Flow-Weight-Sharing" class="headerlink" title="PyTorch: Control Flow + Weight Sharing"></a>PyTorch: Control Flow + Weight Sharing</h3><p>æˆ‘ä»¬ç”¨ä¸€ä¸ªå¾ˆå¥‡æ€ªçš„æ¨¡å‹æ¥æ¼”ç¤ºåŠ¨æ€å›¾å’Œæƒé‡å…±äº«ï¼šä¸€ä¸ªå…¨è¿æ¥ ReLU ç½‘ç»œï¼Œåœ¨æ¯æ¬¡å‰å‘ä¼ æ’­çš„æ—¶å€™éšæœºæŒ‡å®šä¸€ä¸ª 0~3 çš„æ•°å­—å¹¶ä»¥è¿™ä¸ªæ•°å­—ä½œä¸ºä¸­é—´å±‚çš„å±‚æ•°ï¼Œä¸”è¿™äº›ä¸­é—´å±‚å…±äº«æƒé‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DynamicNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the constructor we construct three nn.Linear instances that we will use</span></span><br><span class="line"><span class="string">        in the forward pass.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.input_linear = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.middle_linear = torch.nn.Linear(H, H)</span><br><span class="line">        self.output_linear = torch.nn.Linear(H, D_out)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3</span></span><br><span class="line"><span class="string">        and reuse the middle_linear Module that many times to compute hidden layer</span></span><br><span class="line"><span class="string">        representations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Since each forward pass builds a dynamic computation graph, we can use normal</span></span><br><span class="line"><span class="string">        Python control-flow operators like loops or conditional statements when</span></span><br><span class="line"><span class="string">        defining the forward pass of the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Here we also see that it is perfectly safe to reuse the same Module many</span></span><br><span class="line"><span class="string">        times when defining a computational graph. This is a big improvement from Lua</span></span><br><span class="line"><span class="string">        Torch, where each Module could be used only once.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        h_relu = self.input_linear(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(random.randint(<span class="number">0</span>, <span class="number">3</span>)):</span><br><span class="line">            h_relu = self.middle_linear(h_relu).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.output_linear(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our model by instantiating the class defined above</span></span><br><span class="line">model = DynamicNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our loss function and an Optimizer. Training this strange model with</span></span><br><span class="line"><span class="comment"># vanilla stochastic gradient descent is tough, so we use momentum</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: Compute predicted y by passing x to the model</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = criterion(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero gradients, perform a backward pass, and update the weights.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<hr>
<p>å‚è€ƒèµ„æ–™ï¼š</p>
<ul>
<li><a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html" target="_blank" rel="noopener">LEARNING PYTORCH WITH EXAMPLES</a> </li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/19/pytorch-data-loading-tutorial/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/19/pytorch-data-loading-tutorial/" class="post-title-link" itemprop="url">PyTorch Data Loading Tutorial</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-19 21:36:18" itemprop="dateCreated datePublished" datetime="2019-06-19T21:36:18+08:00">2019-06-19</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-06-20 17:08:58" itemprop="dateModified" datetime="2019-06-20T17:08:58+08:00">2019-06-20</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡ä¸º <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">DATA LOADING AND PROCESSING TUTORIAL</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/19/pytorch-data-loading-tutorial/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/14/a-60min-blitz-cifar10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/a-60min-blitz-cifar10/" class="post-title-link" itemprop="url">A 60 Minute Blitz å­¦ä¹ ç¬”è®°ï¼šTraining a Classifier</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-14 00:00:56 / ä¿®æ”¹æ—¶é—´ï¼š00:22:49" itemprop="dateCreated datePublished" datetime="2019-06-14T00:00:56+08:00">2019-06-14</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" target="_blank" rel="noopener">Training a Classifier</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/14/a-60min-blitz-cifar10/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/13/a-60min-blitz-neural-networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/13/a-60min-blitz-neural-networks/" class="post-title-link" itemprop="url">A 60 Minute Blitz å­¦ä¹ ç¬”è®°ï¼šNeural Networks</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-13 17:28:08 / ä¿®æ”¹æ—¶é—´ï¼š18:23:31" itemprop="dateCreated datePublished" datetime="2019-06-13T17:28:08+08:00">2019-06-13</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" target="_blank" rel="noopener">NEURAL NETWORKS</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/13/a-60min-blitz-neural-networks/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/12/a-60min-blitz-autograd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/12/a-60min-blitz-autograd/" class="post-title-link" itemprop="url">A 60 Minute Blitz å­¦ä¹ ç¬”è®°ï¼šAutograd</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-12 23:00:46" itemprop="dateCreated datePublished" datetime="2019-06-12T23:00:46+08:00">2019-06-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-06-13 17:53:17" itemprop="dateModified" datetime="2019-06-13T17:53:17+08:00">2019-06-13</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py" target="_blank" rel="noopener">AUTOGRAD: AUTOMATIC DIFFERENTIATION</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/12/a-60min-blitz-autograd/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/12/a-60min-blitz-tensor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/12/a-60min-blitz-tensor/" class="post-title-link" itemprop="url">A 60 Minute Blitz å­¦ä¹ ç¬”è®°ï¼šWhat Is Pytorch</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-12 19:51:15" itemprop="dateCreated datePublished" datetime="2019-06-12T19:51:15+08:00">2019-06-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-06-13 17:53:31" itemprop="dateModified" datetime="2019-06-13T17:53:31+08:00">2019-06-13</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#what-is-pytorch" target="_blank" rel="noopener">WHAT IS PYTORCH?</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/12/a-60min-blitz-tensor/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/12/pytorch-autograd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/12/pytorch-autograd/" class="post-title-link" itemprop="url">Pytorch è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-12 14:57:31 / ä¿®æ”¹æ—¶é—´ï¼š16:03:05" itemprop="dateCreated datePublished" datetime="2019-06-12T14:57:31+08:00">2019-06-12</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pytorch.org/docs/stable/notes/autograd.html" target="_blank" rel="noopener">AUTOGRAD MECHANICS</a> çš„ä¸­æ–‡ç¿»è¯‘ï¼Œæˆªè‡³æœ¬æ–‡å‘å¸ƒæ—¶ <code>pytorch</code> çš„ç¨³å®šç‰ˆæœ¬ä¸º <code>1.1</code></p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/12/pytorch-autograd/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/11/asyncio-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/11/asyncio-5/" class="post-title-link" itemprop="url">Asyncio å­¦ä¹ ç¬”è®°ï¼šä½¿ç”¨æ§åˆ¶ç»“æ„æ„å»ºåç¨‹</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-11 20:24:47 / ä¿®æ”¹æ—¶é—´ï¼š22:30:12" itemprop="dateCreated datePublished" datetime="2019-06-11T20:24:47+08:00">2019-06-11</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡æ˜¯ <a href="https://pymotw.com/3/asyncio/control.html" target="_blank" rel="noopener">Composing Coroutines with Control Structures</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/11/asyncio-5/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/11/asyncio-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/11/asyncio-4/" class="post-title-link" itemprop="url">Asyncio å­¦ä¹ ç¬”è®°ï¼šå¹¶å‘æ‰§è¡Œ Tasks</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-11 15:37:36 / ä¿®æ”¹æ—¶é—´ï¼š20:23:09" itemprop="dateCreated datePublished" datetime="2019-06-11T15:37:36+08:00">2019-06-11</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡ä¸º <a href="https://pymotw.com/3/asyncio/tasks.html" target="_blank" rel="noopener">Executing Tasks Concurrently</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/11/asyncio-4/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/11/asyncio-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Patrick">
      <meta itemprop="description" content="ğŸŒˆ">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pato's raison d'etre">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/11/asyncio-3/" class="post-title-link" itemprop="url">Asyncio å­¦ä¹ ç¬”è®°: ä»¥å¼‚æ­¥æ–¹å¼ç”Ÿæˆæ•°æ®</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-06-11 14:54:14 / ä¿®æ”¹æ—¶é—´ï¼š19:25:53" itemprop="dateCreated datePublished" datetime="2019-06-11T14:54:14+08:00">2019-06-11</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>æœ¬æ–‡ä¸º <a href="https://pymotw.com/3/asyncio/futures.html" target="_blank" rel="noopener">Producing Results Asynchronously</a> çš„å­¦ä¹ ç¬”è®°</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/11/asyncio-3/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="ä¸‹ä¸€é¡µ"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Patrick</p>
              <div class="site-description motion-element" itemprop="description">ğŸŒˆ</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">æ—¥å¿—</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">æ ‡ç­¾</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Patrick</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  



  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
